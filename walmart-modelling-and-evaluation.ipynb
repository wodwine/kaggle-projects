{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "million-smile",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-criterion",
   "metadata": {},
   "source": [
    "#### 1. Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "homeless-collar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Dept</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>IsHoliday</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Week</th>\n",
       "      <th>Month</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>Type_A</th>\n",
       "      <th>Type_B</th>\n",
       "      <th>Type_C</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Size</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24924.50</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.018774</td>\n",
       "      <td>0.078201</td>\n",
       "      <td>0.239209</td>\n",
       "      <td>-1.215487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>50605.27</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.018774</td>\n",
       "      <td>0.078201</td>\n",
       "      <td>0.239209</td>\n",
       "      <td>-1.215487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>13740.12</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.018774</td>\n",
       "      <td>0.078201</td>\n",
       "      <td>0.239209</td>\n",
       "      <td>-1.215487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>39954.04</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.018774</td>\n",
       "      <td>0.078201</td>\n",
       "      <td>0.239209</td>\n",
       "      <td>-1.215487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>32229.38</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.018774</td>\n",
       "      <td>0.078201</td>\n",
       "      <td>0.239209</td>\n",
       "      <td>-1.215487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421565</th>\n",
       "      <td>45</td>\n",
       "      <td>93</td>\n",
       "      <td>2487.80</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-10-26</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.539003</td>\n",
       "      <td>0.379281</td>\n",
       "      <td>-0.303489</td>\n",
       "      <td>1.294317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421566</th>\n",
       "      <td>45</td>\n",
       "      <td>94</td>\n",
       "      <td>5203.31</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-10-26</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.539003</td>\n",
       "      <td>0.379281</td>\n",
       "      <td>-0.303489</td>\n",
       "      <td>1.294317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421567</th>\n",
       "      <td>45</td>\n",
       "      <td>95</td>\n",
       "      <td>56017.47</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-10-26</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.539003</td>\n",
       "      <td>0.379281</td>\n",
       "      <td>-0.303489</td>\n",
       "      <td>1.294317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421568</th>\n",
       "      <td>45</td>\n",
       "      <td>97</td>\n",
       "      <td>6817.48</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-10-26</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.539003</td>\n",
       "      <td>0.379281</td>\n",
       "      <td>-0.303489</td>\n",
       "      <td>1.294317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421569</th>\n",
       "      <td>45</td>\n",
       "      <td>98</td>\n",
       "      <td>1076.80</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-10-26</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.539003</td>\n",
       "      <td>0.379281</td>\n",
       "      <td>-0.303489</td>\n",
       "      <td>1.294317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>421570 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Store  Dept  Weekly_Sales  IsHoliday    DateTime  Week  Month  \\\n",
       "0           1     1      24924.50          0  2010-02-05     5      2   \n",
       "1           1     2      50605.27          0  2010-02-05     5      2   \n",
       "2           1     3      13740.12          0  2010-02-05     5      2   \n",
       "3           1     4      39954.04          0  2010-02-05     5      2   \n",
       "4           1     5      32229.38          0  2010-02-05     5      2   \n",
       "...       ...   ...           ...        ...         ...   ...    ...   \n",
       "421565     45    93       2487.80          0  2012-10-26    43     10   \n",
       "421566     45    94       5203.31          0  2012-10-26    43     10   \n",
       "421567     45    95      56017.47          0  2012-10-26    43     10   \n",
       "421568     45    97       6817.48          0  2012-10-26    43     10   \n",
       "421569     45    98       1076.80          0  2012-10-26    43     10   \n",
       "\n",
       "        SpecialDay  Type_A  Type_B  Type_C       CPI  Unemployment      Size  \\\n",
       "0               -1       1       0       0  1.018774      0.078201  0.239209   \n",
       "1               -1       1       0       0  1.018774      0.078201  0.239209   \n",
       "2               -1       1       0       0  1.018774      0.078201  0.239209   \n",
       "3               -1       1       0       0  1.018774      0.078201  0.239209   \n",
       "4               -1       1       0       0  1.018774      0.078201  0.239209   \n",
       "...            ...     ...     ...     ...       ...           ...       ...   \n",
       "421565          -1       0       1       0  0.539003      0.379281 -0.303489   \n",
       "421566          -1       0       1       0  0.539003      0.379281 -0.303489   \n",
       "421567          -1       0       1       0  0.539003      0.379281 -0.303489   \n",
       "421568          -1       0       1       0  0.539003      0.379281 -0.303489   \n",
       "421569          -1       0       1       0  0.539003      0.379281 -0.303489   \n",
       "\n",
       "            Year  \n",
       "0      -1.215487  \n",
       "1      -1.215487  \n",
       "2      -1.215487  \n",
       "3      -1.215487  \n",
       "4      -1.215487  \n",
       "...          ...  \n",
       "421565  1.294317  \n",
       "421566  1.294317  \n",
       "421567  1.294317  \n",
       "421568  1.294317  \n",
       "421569  1.294317  \n",
       "\n",
       "[421570 rows x 15 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/walmart-preprocessing.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-suffering",
   "metadata": {},
   "source": [
    "#### 2. Define X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "perceived-dylan",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop([\"Weekly_Sales\",\"DateTime\"],axis=1)\n",
    "y = data[\"Weekly_Sales\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "municipal-thompson",
   "metadata": {},
   "source": [
    "#### 3. Features Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sunset-fight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>Weekly_Sales</td>   <th>  R-squared:         </th>  <td>   0.090</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.089</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   3454.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 19 Apr 2021</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:24:56</td>     <th>  Log-Likelihood:    </th> <td>-4.8070e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>421570</td>      <th>  AIC:               </th>  <td>9.614e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>421557</td>      <th>  BIC:               </th>  <td>9.614e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    12</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>        <td>  1.03e+04</td> <td>  142.214</td> <td>   72.446</td> <td> 0.000</td> <td>    1e+04</td> <td> 1.06e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Store</th>        <td> -143.3891</td> <td>    3.051</td> <td>  -47.003</td> <td> 0.000</td> <td> -149.368</td> <td> -137.410</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Dept</th>         <td>  110.3523</td> <td>    1.095</td> <td>  100.737</td> <td> 0.000</td> <td>  108.205</td> <td>  112.499</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>IsHoliday</th>    <td> 1659.7048</td> <td>  306.748</td> <td>    5.411</td> <td> 0.000</td> <td> 1058.488</td> <td> 2260.922</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Week</th>         <td> -103.3617</td> <td>   27.496</td> <td>   -3.759</td> <td> 0.000</td> <td> -157.253</td> <td>  -49.471</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Month</th>        <td>  645.5361</td> <td>  119.408</td> <td>    5.406</td> <td> 0.000</td> <td>  411.501</td> <td>  879.571</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SpecialDay</th>   <td> -363.7994</td> <td>  123.572</td> <td>   -2.944</td> <td> 0.003</td> <td> -605.997</td> <td> -121.602</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Type_A</th>       <td> 1613.6161</td> <td>   90.111</td> <td>   17.907</td> <td> 0.000</td> <td> 1437.002</td> <td> 1790.230</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Type_B</th>       <td> 1252.7281</td> <td>   65.907</td> <td>   19.007</td> <td> 0.000</td> <td> 1123.552</td> <td> 1381.904</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Type_C</th>       <td> 7436.4425</td> <td>  127.610</td> <td>   58.275</td> <td> 0.000</td> <td> 7186.331</td> <td> 7686.554</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CPI</th>          <td> -944.2025</td> <td>   36.147</td> <td>  -26.121</td> <td> 0.000</td> <td>-1015.050</td> <td> -873.355</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Unemployment</th> <td> -436.4870</td> <td>   36.871</td> <td>  -11.838</td> <td> 0.000</td> <td> -508.753</td> <td> -364.221</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Size</th>         <td> 6027.3142</td> <td>   58.112</td> <td>  103.718</td> <td> 0.000</td> <td> 5913.416</td> <td> 6141.213</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Year</th>         <td> -104.1357</td> <td>   35.540</td> <td>   -2.930</td> <td> 0.003</td> <td> -173.792</td> <td>  -34.479</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>296928.884</td> <th>  Durbin-Watson:     </th>  <td>   1.321</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>   <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>9030579.636</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>            <td> 3.020</td>   <th>  Prob(JB):          </th>  <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>        <td>24.855</td>   <th>  Cond. No.          </th>  <td>1.47e+16</td>  \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 7.53e-24. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:           Weekly_Sales   R-squared:                       0.090\n",
       "Model:                            OLS   Adj. R-squared:                  0.089\n",
       "Method:                 Least Squares   F-statistic:                     3454.\n",
       "Date:                Mon, 19 Apr 2021   Prob (F-statistic):               0.00\n",
       "Time:                        12:24:56   Log-Likelihood:            -4.8070e+06\n",
       "No. Observations:              421570   AIC:                         9.614e+06\n",
       "Df Residuals:                  421557   BIC:                         9.614e+06\n",
       "Df Model:                          12                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "const          1.03e+04    142.214     72.446      0.000       1e+04    1.06e+04\n",
       "Store         -143.3891      3.051    -47.003      0.000    -149.368    -137.410\n",
       "Dept           110.3523      1.095    100.737      0.000     108.205     112.499\n",
       "IsHoliday     1659.7048    306.748      5.411      0.000    1058.488    2260.922\n",
       "Week          -103.3617     27.496     -3.759      0.000    -157.253     -49.471\n",
       "Month          645.5361    119.408      5.406      0.000     411.501     879.571\n",
       "SpecialDay    -363.7994    123.572     -2.944      0.003    -605.997    -121.602\n",
       "Type_A        1613.6161     90.111     17.907      0.000    1437.002    1790.230\n",
       "Type_B        1252.7281     65.907     19.007      0.000    1123.552    1381.904\n",
       "Type_C        7436.4425    127.610     58.275      0.000    7186.331    7686.554\n",
       "CPI           -944.2025     36.147    -26.121      0.000   -1015.050    -873.355\n",
       "Unemployment  -436.4870     36.871    -11.838      0.000    -508.753    -364.221\n",
       "Size          6027.3142     58.112    103.718      0.000    5913.416    6141.213\n",
       "Year          -104.1357     35.540     -2.930      0.003    -173.792     -34.479\n",
       "==============================================================================\n",
       "Omnibus:                   296928.884   Durbin-Watson:                   1.321\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          9030579.636\n",
       "Skew:                           3.020   Prob(JB):                         0.00\n",
       "Kurtosis:                      24.855   Cond. No.                     1.47e+16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 7.53e-24. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "x = sm.add_constant(X)\n",
    "sum_ = sm.OLS(y,x).fit()\n",
    "sum_.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atlantic-compatibility",
   "metadata": {},
   "source": [
    "You can see that in the preprocessing notebook, we dropped the irrelavant data out. So the above statistics are better when seeing its individual p-value. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-polymer",
   "metadata": {},
   "source": [
    "#### 4. Split the data into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "magnetic-arcade",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cross-acrylic",
   "metadata": {},
   "source": [
    "#### 5. Build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "lesbian-signal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9755256630872119"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(n_jobs=-1)\n",
    "rf.fit(X_train,y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "rf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-manner",
   "metadata": {},
   "source": [
    "#### 6. Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acute-spending",
   "metadata": {},
   "source": [
    "Regression model evaluation metrics\n",
    "\n",
    "1. Root Mean Sqaure Error (RMSE).\n",
    "2. Mean Absolut Error (MAE).\n",
    "3. R^2 (R-Square) or coefficient of determination.\n",
    "4. Cross validation: accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "computational-still",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,r2_score,mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def evaluate_model(model,y_test,y_pred,X=None,y=None):\n",
    "    rmse = mean_squared_error(y_test,y_pred,squared=False)\n",
    "    mae = mean_absolute_error(y_test,y_pred)\n",
    "    r2 = r2_score(y_test,y_pred)\n",
    "    print(f\"Root Mean Squared Error: {rmse:.2f}\")\n",
    "    print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "    print(f\"R-Squared: {r2*100:.2f}%\")\n",
    "    if X is not None and y is not None:\n",
    "        cvs_acc = cross_val_score(model,X,y,cv=5)\n",
    "        print(f\"The cross validation accuracy: {np.mean(cvs_acc)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "recorded-architecture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 3585.65\n",
      "Mean Absolute Error: 1395.45\n",
      "R-Squared: 97.55%\n",
      "The cross validation accuracy: 71.24%\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(rf,y_test,y_pred,X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standing-belfast",
   "metadata": {},
   "source": [
    "#### Additional-Features Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "headed-sally",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(5,5))\n",
    "\n",
    "sorted_idx = rf.feature_importances_.argsort()\n",
    "ax.barh(X.columns[sorted_idx], rf.feature_importances_[sorted_idx])\n",
    "ax.set_title(f\"Random Forest Feature Importance\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "several-judges",
   "metadata": {},
   "source": [
    "#### 7. Tune the model with Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving-consistency",
   "metadata": {},
   "source": [
    "To tune the model parameters, we can't use all the data because it will take long long time to run all possible combination. So we decide to use only 10 percent of the data to find the best parameters. This time we use GridSearchCV to perform the tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "weird-luther",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_10 = data.sample(int(len(data)*0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "twenty-oasis",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_10 = data_10.drop([\"Weekly_Sales\",\"DateTime\"],axis=1)\n",
    "y_10 = data_10[\"Weekly_Sales\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "unique-bridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_10,X_test_10,y_train_10,y_test_10 = train_test_split(X_10,y_10,test_size=0.2,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "about-haiti",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.6s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.6s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.7s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   4.9s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   4.7s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   4.7s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   4.7s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   4.6s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  11.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  10.9s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  10.9s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  10.9s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  11.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   4.7s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   4.6s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   4.8s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   4.7s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   4.7s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=500; total time=  11.4s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=500; total time=  11.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=500; total time=  10.9s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=500; total time=  10.9s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=500; total time=  10.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   3.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   3.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   3.7s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   3.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   3.7s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   1.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   1.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   1.5s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   1.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   1.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=500; total time=   3.5s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=500; total time=   3.5s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=500; total time=   3.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=500; total time=   3.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=500; total time=   3.5s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV,train_test_split\n",
    "\n",
    "grid = {\"n_estimators\":[100,200,500],\n",
    "       \"max_depth\":[20],\n",
    "       \"max_features\":[\"auto\",\"sqrt\"],\n",
    "       \"min_samples_split\":[2,4],\n",
    "       \"min_samples_leaf\":[4]}\n",
    "\n",
    "model = RandomForestRegressor(n_jobs=-1)\n",
    "\n",
    "gs_model = GridSearchCV(estimator=model,\n",
    "                       param_grid=grid,\n",
    "                       cv=5,\n",
    "                       verbose=2)\n",
    "\n",
    "gs_model.fit(X_train_10,y_train_10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ranging-buffalo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 20,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 4,\n",
       " 'min_samples_split': 4,\n",
       " 'n_estimators': 200}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "complimentary-antarctica",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_y_preds = gs_model.predict(X_test_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "featured-campus",
   "metadata": {},
   "source": [
    "#### 8. Use the best parameters to build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "lucky-psychiatry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9717973780336344"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_best_params = RandomForestRegressor(max_depth=20,\n",
    "                           max_features=\"auto\",\n",
    "                           min_samples_leaf=4,\n",
    "                           min_samples_split=4,\n",
    "                           n_estimators=500,\n",
    "                           n_jobs=-1)\n",
    "rf_best_params.fit(X_train,y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "rf_best_params.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "demonstrated-bidding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 3585.65\n",
      "Mean Absolute Error: 1395.45\n",
      "R-Squared: 97.55%\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(rf_best_params,y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspected-shift",
   "metadata": {},
   "source": [
    "As you can see the best scores are from the first model that we built with defualt parameters. That's why Random Forest is a good model and easy to use because the defualt model usually gives the good result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latest-aggregate",
   "metadata": {},
   "source": [
    "#### 9. Try with other models\n",
    "\n",
    "1. Linear Regression.\n",
    "2. K-Nearest Neighbors.\n",
    "3. Decision Tree .\n",
    "4. Artificial Neural Networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "moderate-stuff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 21831.84\n",
      "Mean Absolute Error: 14597.85\n",
      "R-Squared: 9.27%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train,y_train)\n",
    "y_reg = reg.predict(X_test)\n",
    "evaluate_model(reg,y_test,y_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "departmental-aurora",
   "metadata": {},
   "source": [
    "As we can see from RMSE of Linear Regression, the output is not good enough because the some columns in the data might not be a linear. So when we apply Linear Regression to perform a model, the output is what we expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "developed-filename",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 12552.49\n",
      "Mean Absolute Error: 6873.98\n",
      "R-Squared: 70.01%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor # KSN\n",
    "\n",
    "knn = KNeighborsRegressor()\n",
    "knn.fit(X_train,y_train)\n",
    "y_knn = knn.predict(X_test)\n",
    "evaluate_model(knn,y_test,y_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dying-stranger",
   "metadata": {},
   "source": [
    "As we can see from RMSE of K-Nearest Neighbors, the output is better than Linear Regression but it's not that good. Maybe the data might perform well in this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "expanded-nicholas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 4531.43\n",
      "Mean Absolute Error: 1720.53\n",
      "R-Squared: 96.09%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dt = DecisionTreeRegressor()\n",
    "dt.fit(X_train,y_train)\n",
    "y_dt = dt.predict(X_test)\n",
    "evaluate_model(dt,y_test,y_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "false-chassis",
   "metadata": {},
   "source": [
    "As we can see from RMSE of Decision Tree, we get the better score compare to the two models before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cellular-commons",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "33726/33726 [==============================] - 23s 685us/step - loss: 489719988.2805 - mean_squared_error: 489719988.2805 - val_loss: 426777568.0000 - val_mean_squared_error: 426777568.0000\n",
      "Epoch 2/150\n",
      "33726/33726 [==============================] - 24s 713us/step - loss: 413646636.8837 - mean_squared_error: 413646636.8837 - val_loss: 407095936.0000 - val_mean_squared_error: 407095936.0000\n",
      "Epoch 3/150\n",
      "33726/33726 [==============================] - 22s 665us/step - loss: 396083237.5438 - mean_squared_error: 396083237.5438 - val_loss: 398697216.0000 - val_mean_squared_error: 398697216.0000\n",
      "Epoch 4/150\n",
      "33726/33726 [==============================] - 24s 711us/step - loss: 392965305.9583 - mean_squared_error: 392965305.9583 - val_loss: 391564256.0000 - val_mean_squared_error: 391564256.0000\n",
      "Epoch 5/150\n",
      "33726/33726 [==============================] - 26s 773us/step - loss: 378137601.3798 - mean_squared_error: 378137601.3798 - val_loss: 385215776.0000 - val_mean_squared_error: 385215712.0000\n",
      "Epoch 6/150\n",
      "33726/33726 [==============================] - 29s 853us/step - loss: 372731923.6159 - mean_squared_error: 372731923.6045 - val_loss: 381632768.0000 - val_mean_squared_error: 381632768.0000\n",
      "Epoch 7/150\n",
      "33726/33726 [==============================] - 29s 857us/step - loss: 368581059.1481 - mean_squared_error: 368581059.1481 - val_loss: 377306048.0000 - val_mean_squared_error: 377306048.0000\n",
      "Epoch 8/150\n",
      "33726/33726 [==============================] - 24s 713us/step - loss: 366861775.8933 - mean_squared_error: 366861782.3527 - val_loss: 374188832.0000 - val_mean_squared_error: 374188832.0000\n",
      "Epoch 9/150\n",
      "33726/33726 [==============================] - 24s 704us/step - loss: 368145322.8722 - mean_squared_error: 368145322.8722 - val_loss: 372887936.0000 - val_mean_squared_error: 372887936.0000\n",
      "Epoch 10/150\n",
      "33726/33726 [==============================] - 24s 713us/step - loss: 366060043.1047 - mean_squared_error: 366060043.1066 - val_loss: 367875904.0000 - val_mean_squared_error: 367875936.0000\n",
      "Epoch 11/150\n",
      "33726/33726 [==============================] - 25s 727us/step - loss: 355962330.7674 - mean_squared_error: 355962330.7674 - val_loss: 374138336.0000 - val_mean_squared_error: 374138336.0000\n",
      "Epoch 12/150\n",
      "33726/33726 [==============================] - 25s 733us/step - loss: 368685774.8036 - mean_squared_error: 368685774.8040 - val_loss: 364986848.0000 - val_mean_squared_error: 364986848.0000\n",
      "Epoch 13/150\n",
      "33726/33726 [==============================] - 26s 775us/step - loss: 359753103.8605 - mean_squared_error: 359753103.8605 - val_loss: 363445600.0000 - val_mean_squared_error: 363445600.0000\n",
      "Epoch 14/150\n",
      "33726/33726 [==============================] - 26s 781us/step - loss: 358709607.3532 - mean_squared_error: 358709607.3532 - val_loss: 361623968.0000 - val_mean_squared_error: 361623968.0000\n",
      "Epoch 15/150\n",
      "33726/33726 [==============================] - 25s 744us/step - loss: 355734752.8383 - mean_squared_error: 355734752.8383 - val_loss: 361647616.0000 - val_mean_squared_error: 361647616.0000\n",
      "Epoch 16/150\n",
      "33726/33726 [==============================] - 25s 731us/step - loss: 354073822.5000 - mean_squared_error: 354073827.7326 - val_loss: 356963776.0000 - val_mean_squared_error: 356963776.0000\n",
      "Epoch 17/150\n",
      "33726/33726 [==============================] - 25s 739us/step - loss: 351192937.8418 - mean_squared_error: 351192937.8418 - val_loss: 357373216.0000 - val_mean_squared_error: 357373216.0000\n",
      "Epoch 18/150\n",
      "33726/33726 [==============================] - 26s 762us/step - loss: 346644937.9136 - mean_squared_error: 346644937.9293 - val_loss: 353403936.0000 - val_mean_squared_error: 353403936.0000\n",
      "Epoch 19/150\n",
      "33726/33726 [==============================] - 27s 808us/step - loss: 346782396.6401 - mean_squared_error: 346782396.6240 - val_loss: 351438176.0000 - val_mean_squared_error: 351438176.0000\n",
      "Epoch 20/150\n",
      "33726/33726 [==============================] - 26s 781us/step - loss: 346065408.0417 - mean_squared_error: 346065406.9468 - val_loss: 351216960.0000 - val_mean_squared_error: 351216960.0000\n",
      "Epoch 21/150\n",
      "33726/33726 [==============================] - 23s 672us/step - loss: 346794590.0777 - mean_squared_error: 346794590.0796 - val_loss: 348718656.0000 - val_mean_squared_error: 348718656.0000\n",
      "Epoch 22/150\n",
      "33726/33726 [==============================] - 23s 671us/step - loss: 339915906.4805 - mean_squared_error: 339915906.4824 - val_loss: 347644992.0000 - val_mean_squared_error: 347644992.0000\n",
      "Epoch 23/150\n",
      "33726/33726 [==============================] - 25s 734us/step - loss: 337677874.9194 - mean_squared_error: 337677874.9194 - val_loss: 346506464.0000 - val_mean_squared_error: 346506464.0000\n",
      "Epoch 24/150\n",
      "33726/33726 [==============================] - 26s 785us/step - loss: 345749182.9781 - mean_squared_error: 345749182.9895 - val_loss: 346344960.0000 - val_mean_squared_error: 346344960.0000\n",
      "Epoch 25/150\n",
      "33726/33726 [==============================] - 30s 880us/step - loss: 335880070.3028 - mean_squared_error: 335880067.9432 - val_loss: 350260288.0000 - val_mean_squared_error: 350260288.0000\n",
      "Epoch 26/150\n",
      "33726/33726 [==============================] - 24s 711us/step - loss: 343731010.9137 - mean_squared_error: 343731010.9137 - val_loss: 344318496.0000 - val_mean_squared_error: 344318496.0000\n",
      "Epoch 27/150\n",
      "33726/33726 [==============================] - 22s 664us/step - loss: 339327740.8899 - mean_squared_error: 339327740.8917 - val_loss: 343209504.0000 - val_mean_squared_error: 343209504.0000\n",
      "Epoch 28/150\n",
      "33726/33726 [==============================] - 24s 710us/step - loss: 333683805.6755 - mean_squared_error: 333683805.8073 - val_loss: 344974528.0000 - val_mean_squared_error: 344974528.0000\n",
      "Epoch 29/150\n",
      "33726/33726 [==============================] - 28s 826us/step - loss: 333716205.0758 - mean_squared_error: 333716205.0654 - val_loss: 342402016.0000 - val_mean_squared_error: 342402016.0000\n",
      "Epoch 30/150\n",
      "33726/33726 [==============================] - 27s 796us/step - loss: 331118006.2663 - mean_squared_error: 331118006.2682 - val_loss: 341632288.0000 - val_mean_squared_error: 341632288.0000\n",
      "Epoch 31/150\n",
      "33726/33726 [==============================] - 26s 758us/step - loss: 326039641.6177 - mean_squared_error: 326039645.7862 - val_loss: 339210880.0000 - val_mean_squared_error: 339210880.0000\n",
      "Epoch 32/150\n",
      "33726/33726 [==============================] - 27s 807us/step - loss: 330847123.5162 - mean_squared_error: 330847123.5162 - val_loss: 342756768.0000 - val_mean_squared_error: 342756768.0000\n",
      "Epoch 33/150\n",
      "33726/33726 [==============================] - 36s 1ms/step - loss: 331172245.5429 - mean_squared_error: 331172245.5429 - val_loss: 349395936.0000 - val_mean_squared_error: 349395936.0000\n",
      "Epoch 34/150\n",
      "33726/33726 [==============================] - 28s 842us/step - loss: 329944294.1994 - mean_squared_error: 329944294.1994 - val_loss: 339448320.0000 - val_mean_squared_error: 339448320.0000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Dense(units=50,input_dim=X_train.shape[1],activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(units=50,activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(units=1,activation=\"linear\"))\n",
    "model.compile(optimizer=\"adam\",loss='mean_squared_error',metrics=[\"mean_squared_error\"])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_mean_squared_error\",patience=3)\n",
    "\n",
    "r = model.fit(x=X_train,y=y_train,epochs=150,batch_size=10,validation_data=(X_test,y_test),callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "reverse-meter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 18424.11\n"
     ]
    }
   ],
   "source": [
    "_,mean_squared_error = model.evaluate(X_test,y_test,verbose=0)\n",
    "y_ann = model.predict(X_test).reshape(-1,)\n",
    "print(f\"Root Mean Squared Error: {np.sqrt(mean_squared_error):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-pioneer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
