{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "million-smile",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-criterion",
   "metadata": {},
   "source": [
    "#### 1. Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "homeless-collar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Dept</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>IsHoliday</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Week</th>\n",
       "      <th>Month</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>Type_A</th>\n",
       "      <th>Type_B</th>\n",
       "      <th>Type_C</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Size</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24924.50</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.018774</td>\n",
       "      <td>0.078201</td>\n",
       "      <td>0.239209</td>\n",
       "      <td>-1.215487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>50605.27</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.018774</td>\n",
       "      <td>0.078201</td>\n",
       "      <td>0.239209</td>\n",
       "      <td>-1.215487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>13740.12</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.018774</td>\n",
       "      <td>0.078201</td>\n",
       "      <td>0.239209</td>\n",
       "      <td>-1.215487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>39954.04</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.018774</td>\n",
       "      <td>0.078201</td>\n",
       "      <td>0.239209</td>\n",
       "      <td>-1.215487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>32229.38</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.018774</td>\n",
       "      <td>0.078201</td>\n",
       "      <td>0.239209</td>\n",
       "      <td>-1.215487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421565</th>\n",
       "      <td>45</td>\n",
       "      <td>93</td>\n",
       "      <td>2487.80</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-10-26</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.539003</td>\n",
       "      <td>0.379281</td>\n",
       "      <td>-0.303489</td>\n",
       "      <td>1.294317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421566</th>\n",
       "      <td>45</td>\n",
       "      <td>94</td>\n",
       "      <td>5203.31</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-10-26</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.539003</td>\n",
       "      <td>0.379281</td>\n",
       "      <td>-0.303489</td>\n",
       "      <td>1.294317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421567</th>\n",
       "      <td>45</td>\n",
       "      <td>95</td>\n",
       "      <td>56017.47</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-10-26</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.539003</td>\n",
       "      <td>0.379281</td>\n",
       "      <td>-0.303489</td>\n",
       "      <td>1.294317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421568</th>\n",
       "      <td>45</td>\n",
       "      <td>97</td>\n",
       "      <td>6817.48</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-10-26</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.539003</td>\n",
       "      <td>0.379281</td>\n",
       "      <td>-0.303489</td>\n",
       "      <td>1.294317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421569</th>\n",
       "      <td>45</td>\n",
       "      <td>98</td>\n",
       "      <td>1076.80</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-10-26</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.539003</td>\n",
       "      <td>0.379281</td>\n",
       "      <td>-0.303489</td>\n",
       "      <td>1.294317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>421570 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Store  Dept  Weekly_Sales  IsHoliday    DateTime  Week  Month  \\\n",
       "0           1     1      24924.50          0  2010-02-05     5      2   \n",
       "1           1     2      50605.27          0  2010-02-05     5      2   \n",
       "2           1     3      13740.12          0  2010-02-05     5      2   \n",
       "3           1     4      39954.04          0  2010-02-05     5      2   \n",
       "4           1     5      32229.38          0  2010-02-05     5      2   \n",
       "...       ...   ...           ...        ...         ...   ...    ...   \n",
       "421565     45    93       2487.80          0  2012-10-26    43     10   \n",
       "421566     45    94       5203.31          0  2012-10-26    43     10   \n",
       "421567     45    95      56017.47          0  2012-10-26    43     10   \n",
       "421568     45    97       6817.48          0  2012-10-26    43     10   \n",
       "421569     45    98       1076.80          0  2012-10-26    43     10   \n",
       "\n",
       "        SpecialDay  Type_A  Type_B  Type_C       CPI  Unemployment      Size  \\\n",
       "0               -1       1       0       0  1.018774      0.078201  0.239209   \n",
       "1               -1       1       0       0  1.018774      0.078201  0.239209   \n",
       "2               -1       1       0       0  1.018774      0.078201  0.239209   \n",
       "3               -1       1       0       0  1.018774      0.078201  0.239209   \n",
       "4               -1       1       0       0  1.018774      0.078201  0.239209   \n",
       "...            ...     ...     ...     ...       ...           ...       ...   \n",
       "421565          -1       0       1       0  0.539003      0.379281 -0.303489   \n",
       "421566          -1       0       1       0  0.539003      0.379281 -0.303489   \n",
       "421567          -1       0       1       0  0.539003      0.379281 -0.303489   \n",
       "421568          -1       0       1       0  0.539003      0.379281 -0.303489   \n",
       "421569          -1       0       1       0  0.539003      0.379281 -0.303489   \n",
       "\n",
       "            Year  \n",
       "0      -1.215487  \n",
       "1      -1.215487  \n",
       "2      -1.215487  \n",
       "3      -1.215487  \n",
       "4      -1.215487  \n",
       "...          ...  \n",
       "421565  1.294317  \n",
       "421566  1.294317  \n",
       "421567  1.294317  \n",
       "421568  1.294317  \n",
       "421569  1.294317  \n",
       "\n",
       "[421570 rows x 15 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/walmart-preprocessing.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-suffering",
   "metadata": {},
   "source": [
    "#### 2. Define X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "perceived-dylan",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop([\"Weekly_Sales\",\"DateTime\"],axis=1)\n",
    "y = data[\"Weekly_Sales\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "municipal-thompson",
   "metadata": {},
   "source": [
    "#### 3. Features Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "sunset-fight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>Weekly_Sales</td>   <th>  R-squared:         </th>  <td>   0.090</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.089</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   3454.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 19 Apr 2021</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:32:21</td>     <th>  Log-Likelihood:    </th> <td>-4.8070e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>421570</td>      <th>  AIC:               </th>  <td>9.614e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>421557</td>      <th>  BIC:               </th>  <td>9.614e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    12</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>        <td>  1.03e+04</td> <td>  142.214</td> <td>   72.446</td> <td> 0.000</td> <td>    1e+04</td> <td> 1.06e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Store</th>        <td> -143.3891</td> <td>    3.051</td> <td>  -47.003</td> <td> 0.000</td> <td> -149.368</td> <td> -137.410</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Dept</th>         <td>  110.3523</td> <td>    1.095</td> <td>  100.737</td> <td> 0.000</td> <td>  108.205</td> <td>  112.499</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>IsHoliday</th>    <td> 1659.7048</td> <td>  306.748</td> <td>    5.411</td> <td> 0.000</td> <td> 1058.488</td> <td> 2260.922</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Week</th>         <td> -103.3617</td> <td>   27.496</td> <td>   -3.759</td> <td> 0.000</td> <td> -157.253</td> <td>  -49.471</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Month</th>        <td>  645.5361</td> <td>  119.408</td> <td>    5.406</td> <td> 0.000</td> <td>  411.501</td> <td>  879.571</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SpecialDay</th>   <td> -363.7994</td> <td>  123.572</td> <td>   -2.944</td> <td> 0.003</td> <td> -605.997</td> <td> -121.602</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Type_A</th>       <td> 1613.6161</td> <td>   90.111</td> <td>   17.907</td> <td> 0.000</td> <td> 1437.002</td> <td> 1790.230</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Type_B</th>       <td> 1252.7281</td> <td>   65.907</td> <td>   19.007</td> <td> 0.000</td> <td> 1123.552</td> <td> 1381.904</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Type_C</th>       <td> 7436.4425</td> <td>  127.610</td> <td>   58.275</td> <td> 0.000</td> <td> 7186.331</td> <td> 7686.554</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CPI</th>          <td> -944.2025</td> <td>   36.147</td> <td>  -26.121</td> <td> 0.000</td> <td>-1015.050</td> <td> -873.355</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Unemployment</th> <td> -436.4870</td> <td>   36.871</td> <td>  -11.838</td> <td> 0.000</td> <td> -508.753</td> <td> -364.221</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Size</th>         <td> 6027.3142</td> <td>   58.112</td> <td>  103.718</td> <td> 0.000</td> <td> 5913.416</td> <td> 6141.213</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Year</th>         <td> -104.1357</td> <td>   35.540</td> <td>   -2.930</td> <td> 0.003</td> <td> -173.792</td> <td>  -34.479</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>296928.884</td> <th>  Durbin-Watson:     </th>  <td>   1.321</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>   <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>9030579.636</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>            <td> 3.020</td>   <th>  Prob(JB):          </th>  <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>        <td>24.855</td>   <th>  Cond. No.          </th>  <td>1.47e+16</td>  \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 7.53e-24. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:           Weekly_Sales   R-squared:                       0.090\n",
       "Model:                            OLS   Adj. R-squared:                  0.089\n",
       "Method:                 Least Squares   F-statistic:                     3454.\n",
       "Date:                Mon, 19 Apr 2021   Prob (F-statistic):               0.00\n",
       "Time:                        15:32:21   Log-Likelihood:            -4.8070e+06\n",
       "No. Observations:              421570   AIC:                         9.614e+06\n",
       "Df Residuals:                  421557   BIC:                         9.614e+06\n",
       "Df Model:                          12                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "const          1.03e+04    142.214     72.446      0.000       1e+04    1.06e+04\n",
       "Store         -143.3891      3.051    -47.003      0.000    -149.368    -137.410\n",
       "Dept           110.3523      1.095    100.737      0.000     108.205     112.499\n",
       "IsHoliday     1659.7048    306.748      5.411      0.000    1058.488    2260.922\n",
       "Week          -103.3617     27.496     -3.759      0.000    -157.253     -49.471\n",
       "Month          645.5361    119.408      5.406      0.000     411.501     879.571\n",
       "SpecialDay    -363.7994    123.572     -2.944      0.003    -605.997    -121.602\n",
       "Type_A        1613.6161     90.111     17.907      0.000    1437.002    1790.230\n",
       "Type_B        1252.7281     65.907     19.007      0.000    1123.552    1381.904\n",
       "Type_C        7436.4425    127.610     58.275      0.000    7186.331    7686.554\n",
       "CPI           -944.2025     36.147    -26.121      0.000   -1015.050    -873.355\n",
       "Unemployment  -436.4870     36.871    -11.838      0.000    -508.753    -364.221\n",
       "Size          6027.3142     58.112    103.718      0.000    5913.416    6141.213\n",
       "Year          -104.1357     35.540     -2.930      0.003    -173.792     -34.479\n",
       "==============================================================================\n",
       "Omnibus:                   296928.884   Durbin-Watson:                   1.321\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          9030579.636\n",
       "Skew:                           3.020   Prob(JB):                         0.00\n",
       "Kurtosis:                      24.855   Cond. No.                     1.47e+16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 7.53e-24. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "x = sm.add_constant(X)\n",
    "sum_ = sm.OLS(y,x).fit()\n",
    "sum_.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atlantic-compatibility",
   "metadata": {},
   "source": [
    "You can see that in the preprocessing notebook, we dropped the irrelavant data out. So the above statistics are better when seeing its individual p-value. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-polymer",
   "metadata": {},
   "source": [
    "#### 4. Split the data into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "magnetic-arcade",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cross-acrylic",
   "metadata": {},
   "source": [
    "#### 5. Build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "lesbian-signal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9756344982317652"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(n_jobs=-1)\n",
    "rf.fit(X_train,y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "rf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-manner",
   "metadata": {},
   "source": [
    "#### 6. Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acute-spending",
   "metadata": {},
   "source": [
    "Regression model evaluation metrics\n",
    "\n",
    "1. Root Mean Sqaure Error (RMSE).\n",
    "2. Mean Absolut Error (MAE).\n",
    "3. R^2 (R-Square) or coefficient of determination.\n",
    "4. Cross validation: accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "computational-still",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,r2_score,mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def evaluate_model(model,y_test,y_pred,X=None,y=None):\n",
    "    rmse = mean_squared_error(y_test,y_pred,squared=False)\n",
    "    mae = mean_absolute_error(y_test,y_pred)\n",
    "    r2 = r2_score(y_test,y_pred)\n",
    "    print(f\"Root Mean Squared Error: {rmse:.2f}\")\n",
    "    print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "    print(f\"R-Squared: {r2*100:.2f}%\")\n",
    "    if X is not None and y is not None:\n",
    "        cvs_acc = cross_val_score(model,X,y,cv=5)\n",
    "        print(f\"The cross validation accuracy: {np.mean(cvs_acc)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "recorded-architecture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 3585.65\n",
      "Mean Absolute Error: 1395.45\n",
      "R-Squared: 97.55%\n",
      "The cross validation accuracy: 71.24%\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(rf,y_test,y_pred,X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "weird-revolution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 3577.66\n",
      "Mean Absolute Error: 1394.92\n",
      "R-Squared: 97.56%\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(rf,y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "criminal-financing",
   "metadata": {},
   "source": [
    "#### Additional-Features Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "sorted-vintage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(5,5))\n",
    "\n",
    "sorted_idx = rf.feature_importances_.argsort()\n",
    "ax.barh(X.columns[sorted_idx], rf.feature_importances_[sorted_idx])\n",
    "ax.set_title(f\"Random Forest Feature Importance\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "renewable-share",
   "metadata": {},
   "source": [
    "#### 7. Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "viral-alias",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(rf, open(\"models/RandomForestModel.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "several-judges",
   "metadata": {},
   "source": [
    "#### 8. Tune the model with Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving-consistency",
   "metadata": {},
   "source": [
    "To tune the model parameters, we can't use all the data because it will take long long time to run all possible combination. So we decide to use only 10 percent of the data to find the best parameters. This time we use GridSearchCV to perform the tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "weird-luther",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_10 = data.sample(int(len(data)*0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "twenty-oasis",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_10 = data_10.drop([\"Weekly_Sales\",\"DateTime\"],axis=1)\n",
    "y_10 = data_10[\"Weekly_Sales\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "unique-bridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_10,X_test_10,y_train_10,y_test_10 = train_test_split(X_10,y_10,test_size=0.2,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "about-haiti",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.6s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.6s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.7s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   4.9s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   4.7s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   4.7s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   4.7s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   4.6s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  11.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  10.9s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  10.9s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  10.9s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  11.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   4.7s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   4.6s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   4.8s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   4.7s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   4.7s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=500; total time=  11.4s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=500; total time=  11.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=500; total time=  10.9s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=500; total time=  10.9s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=500; total time=  10.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   3.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   3.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   3.7s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   3.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   3.7s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   1.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   1.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   1.5s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   1.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   1.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=500; total time=   3.5s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=500; total time=   3.5s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=500; total time=   3.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=500; total time=   3.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=500; total time=   3.5s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV,train_test_split\n",
    "\n",
    "grid = {\"n_estimators\":[100,200,500],\n",
    "       \"max_depth\":[20],\n",
    "       \"max_features\":[\"auto\",\"sqrt\"],\n",
    "       \"min_samples_split\":[2,4],\n",
    "       \"min_samples_leaf\":[4]}\n",
    "\n",
    "model = RandomForestRegressor(n_jobs=-1)\n",
    "\n",
    "gs_model = GridSearchCV(estimator=model,\n",
    "                       param_grid=grid,\n",
    "                       cv=5,\n",
    "                       verbose=2)\n",
    "\n",
    "gs_model.fit(X_train_10,y_train_10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ranging-buffalo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 20,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 4,\n",
       " 'min_samples_split': 4,\n",
       " 'n_estimators': 200}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "complimentary-antarctica",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_y_preds = gs_model.predict(X_test_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "featured-campus",
   "metadata": {},
   "source": [
    "#### 8. Use the best parameters to build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "lucky-psychiatry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9717973780336344"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_best_params = RandomForestRegressor(max_depth=20,\n",
    "                           max_features=\"auto\",\n",
    "                           min_samples_leaf=4,\n",
    "                           min_samples_split=4,\n",
    "                           n_estimators=500,\n",
    "                           n_jobs=-1)\n",
    "rf_best_params.fit(X_train,y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "rf_best_params.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "demonstrated-bidding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 3585.65\n",
      "Mean Absolute Error: 1395.45\n",
      "R-Squared: 97.55%\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(rf_best_params,y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspected-shift",
   "metadata": {},
   "source": [
    "As you can see the best scores are from the first model that we built with defualt parameters. That's why Random Forest is a good model and easy to use because the defualt model usually gives the good result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latest-aggregate",
   "metadata": {},
   "source": [
    "#### 9. Try with other models\n",
    "\n",
    "1. Linear Regression.\n",
    "2. K-Nearest Neighbors.\n",
    "3. Decision Tree .\n",
    "4. Artificial Neural Networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "moderate-stuff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 21831.84\n",
      "Mean Absolute Error: 14597.85\n",
      "R-Squared: 9.27%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train,y_train)\n",
    "y_reg = reg.predict(X_test)\n",
    "evaluate_model(reg,y_test,y_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "departmental-aurora",
   "metadata": {},
   "source": [
    "As we can see from RMSE of Linear Regression, the output is not good enough because the some columns in the data might not be a linear. So when we apply Linear Regression to perform a model, the output is what we expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "developed-filename",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 12552.49\n",
      "Mean Absolute Error: 6873.98\n",
      "R-Squared: 70.01%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor # KSN\n",
    "\n",
    "knn = KNeighborsRegressor()\n",
    "knn.fit(X_train,y_train)\n",
    "y_knn = knn.predict(X_test)\n",
    "evaluate_model(knn,y_test,y_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dying-stranger",
   "metadata": {},
   "source": [
    "As we can see from RMSE of K-Nearest Neighbors, the output is better than Linear Regression but it's not that good. Maybe the data might perform well in this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "expanded-nicholas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 4531.43\n",
      "Mean Absolute Error: 1720.53\n",
      "R-Squared: 96.09%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dt = DecisionTreeRegressor()\n",
    "dt.fit(X_train,y_train)\n",
    "y_dt = dt.predict(X_test)\n",
    "evaluate_model(dt,y_test,y_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "false-chassis",
   "metadata": {},
   "source": [
    "As we can see from RMSE of Decision Tree, we get the better score compare to the two models before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cellular-commons",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "33726/33726 [==============================] - 23s 685us/step - loss: 489719988.2805 - mean_squared_error: 489719988.2805 - val_loss: 426777568.0000 - val_mean_squared_error: 426777568.0000\n",
      "Epoch 2/150\n",
      "33726/33726 [==============================] - 24s 713us/step - loss: 413646636.8837 - mean_squared_error: 413646636.8837 - val_loss: 407095936.0000 - val_mean_squared_error: 407095936.0000\n",
      "Epoch 3/150\n",
      "33726/33726 [==============================] - 22s 665us/step - loss: 396083237.5438 - mean_squared_error: 396083237.5438 - val_loss: 398697216.0000 - val_mean_squared_error: 398697216.0000\n",
      "Epoch 4/150\n",
      "33726/33726 [==============================] - 24s 711us/step - loss: 392965305.9583 - mean_squared_error: 392965305.9583 - val_loss: 391564256.0000 - val_mean_squared_error: 391564256.0000\n",
      "Epoch 5/150\n",
      "33726/33726 [==============================] - 26s 773us/step - loss: 378137601.3798 - mean_squared_error: 378137601.3798 - val_loss: 385215776.0000 - val_mean_squared_error: 385215712.0000\n",
      "Epoch 6/150\n",
      "33726/33726 [==============================] - 29s 853us/step - loss: 372731923.6159 - mean_squared_error: 372731923.6045 - val_loss: 381632768.0000 - val_mean_squared_error: 381632768.0000\n",
      "Epoch 7/150\n",
      "33726/33726 [==============================] - 29s 857us/step - loss: 368581059.1481 - mean_squared_error: 368581059.1481 - val_loss: 377306048.0000 - val_mean_squared_error: 377306048.0000\n",
      "Epoch 8/150\n",
      "33726/33726 [==============================] - 24s 713us/step - loss: 366861775.8933 - mean_squared_error: 366861782.3527 - val_loss: 374188832.0000 - val_mean_squared_error: 374188832.0000\n",
      "Epoch 9/150\n",
      "33726/33726 [==============================] - 24s 704us/step - loss: 368145322.8722 - mean_squared_error: 368145322.8722 - val_loss: 372887936.0000 - val_mean_squared_error: 372887936.0000\n",
      "Epoch 10/150\n",
      "33726/33726 [==============================] - 24s 713us/step - loss: 366060043.1047 - mean_squared_error: 366060043.1066 - val_loss: 367875904.0000 - val_mean_squared_error: 367875936.0000\n",
      "Epoch 11/150\n",
      "33726/33726 [==============================] - 25s 727us/step - loss: 355962330.7674 - mean_squared_error: 355962330.7674 - val_loss: 374138336.0000 - val_mean_squared_error: 374138336.0000\n",
      "Epoch 12/150\n",
      "33726/33726 [==============================] - 25s 733us/step - loss: 368685774.8036 - mean_squared_error: 368685774.8040 - val_loss: 364986848.0000 - val_mean_squared_error: 364986848.0000\n",
      "Epoch 13/150\n",
      "33726/33726 [==============================] - 26s 775us/step - loss: 359753103.8605 - mean_squared_error: 359753103.8605 - val_loss: 363445600.0000 - val_mean_squared_error: 363445600.0000\n",
      "Epoch 14/150\n",
      "33726/33726 [==============================] - 26s 781us/step - loss: 358709607.3532 - mean_squared_error: 358709607.3532 - val_loss: 361623968.0000 - val_mean_squared_error: 361623968.0000\n",
      "Epoch 15/150\n",
      "33726/33726 [==============================] - 25s 744us/step - loss: 355734752.8383 - mean_squared_error: 355734752.8383 - val_loss: 361647616.0000 - val_mean_squared_error: 361647616.0000\n",
      "Epoch 16/150\n",
      "33726/33726 [==============================] - 25s 731us/step - loss: 354073822.5000 - mean_squared_error: 354073827.7326 - val_loss: 356963776.0000 - val_mean_squared_error: 356963776.0000\n",
      "Epoch 17/150\n",
      "33726/33726 [==============================] - 25s 739us/step - loss: 351192937.8418 - mean_squared_error: 351192937.8418 - val_loss: 357373216.0000 - val_mean_squared_error: 357373216.0000\n",
      "Epoch 18/150\n",
      "33726/33726 [==============================] - 26s 762us/step - loss: 346644937.9136 - mean_squared_error: 346644937.9293 - val_loss: 353403936.0000 - val_mean_squared_error: 353403936.0000\n",
      "Epoch 19/150\n",
      "33726/33726 [==============================] - 27s 808us/step - loss: 346782396.6401 - mean_squared_error: 346782396.6240 - val_loss: 351438176.0000 - val_mean_squared_error: 351438176.0000\n",
      "Epoch 20/150\n",
      "33726/33726 [==============================] - 26s 781us/step - loss: 346065408.0417 - mean_squared_error: 346065406.9468 - val_loss: 351216960.0000 - val_mean_squared_error: 351216960.0000\n",
      "Epoch 21/150\n",
      "33726/33726 [==============================] - 23s 672us/step - loss: 346794590.0777 - mean_squared_error: 346794590.0796 - val_loss: 348718656.0000 - val_mean_squared_error: 348718656.0000\n",
      "Epoch 22/150\n",
      "33726/33726 [==============================] - 23s 671us/step - loss: 339915906.4805 - mean_squared_error: 339915906.4824 - val_loss: 347644992.0000 - val_mean_squared_error: 347644992.0000\n",
      "Epoch 23/150\n",
      "33726/33726 [==============================] - 25s 734us/step - loss: 337677874.9194 - mean_squared_error: 337677874.9194 - val_loss: 346506464.0000 - val_mean_squared_error: 346506464.0000\n",
      "Epoch 24/150\n",
      "33726/33726 [==============================] - 26s 785us/step - loss: 345749182.9781 - mean_squared_error: 345749182.9895 - val_loss: 346344960.0000 - val_mean_squared_error: 346344960.0000\n",
      "Epoch 25/150\n",
      "33726/33726 [==============================] - 30s 880us/step - loss: 335880070.3028 - mean_squared_error: 335880067.9432 - val_loss: 350260288.0000 - val_mean_squared_error: 350260288.0000\n",
      "Epoch 26/150\n",
      "33726/33726 [==============================] - 24s 711us/step - loss: 343731010.9137 - mean_squared_error: 343731010.9137 - val_loss: 344318496.0000 - val_mean_squared_error: 344318496.0000\n",
      "Epoch 27/150\n",
      "33726/33726 [==============================] - 22s 664us/step - loss: 339327740.8899 - mean_squared_error: 339327740.8917 - val_loss: 343209504.0000 - val_mean_squared_error: 343209504.0000\n",
      "Epoch 28/150\n",
      "33726/33726 [==============================] - 24s 710us/step - loss: 333683805.6755 - mean_squared_error: 333683805.8073 - val_loss: 344974528.0000 - val_mean_squared_error: 344974528.0000\n",
      "Epoch 29/150\n",
      "33726/33726 [==============================] - 28s 826us/step - loss: 333716205.0758 - mean_squared_error: 333716205.0654 - val_loss: 342402016.0000 - val_mean_squared_error: 342402016.0000\n",
      "Epoch 30/150\n",
      "33726/33726 [==============================] - 27s 796us/step - loss: 331118006.2663 - mean_squared_error: 331118006.2682 - val_loss: 341632288.0000 - val_mean_squared_error: 341632288.0000\n",
      "Epoch 31/150\n",
      "33726/33726 [==============================] - 26s 758us/step - loss: 326039641.6177 - mean_squared_error: 326039645.7862 - val_loss: 339210880.0000 - val_mean_squared_error: 339210880.0000\n",
      "Epoch 32/150\n",
      "33726/33726 [==============================] - 27s 807us/step - loss: 330847123.5162 - mean_squared_error: 330847123.5162 - val_loss: 342756768.0000 - val_mean_squared_error: 342756768.0000\n",
      "Epoch 33/150\n",
      "33726/33726 [==============================] - 36s 1ms/step - loss: 331172245.5429 - mean_squared_error: 331172245.5429 - val_loss: 349395936.0000 - val_mean_squared_error: 349395936.0000\n",
      "Epoch 34/150\n",
      "33726/33726 [==============================] - 28s 842us/step - loss: 329944294.1994 - mean_squared_error: 329944294.1994 - val_loss: 339448320.0000 - val_mean_squared_error: 339448320.0000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Dense(units=50,input_dim=X_train.shape[1],activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(units=50,activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(units=1,activation=\"linear\"))\n",
    "model.compile(optimizer=\"adam\",loss='mean_squared_error',metrics=[\"mean_squared_error\"])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_mean_squared_error\",patience=3)\n",
    "\n",
    "r = model.fit(x=X_train,y=y_train,epochs=150,batch_size=10,validation_data=(X_test,y_test),callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "reverse-meter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 18424.11\n"
     ]
    }
   ],
   "source": [
    "_,mean_squared_error = model.evaluate(X_test,y_test,verbose=0)\n",
    "y_ann = model.predict(X_test).reshape(-1,)\n",
    "print(f\"Root Mean Squared Error: {np.sqrt(mean_squared_error):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-pioneer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
