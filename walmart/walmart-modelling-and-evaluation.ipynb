{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "million-smile",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-criterion",
   "metadata": {},
   "source": [
    "#### 1. Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "homeless-collar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Dept</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>IsHoliday</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Week</th>\n",
       "      <th>Month</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>Type_A</th>\n",
       "      <th>Type_B</th>\n",
       "      <th>Type_C</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Size</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24924.50</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.018774</td>\n",
       "      <td>0.078201</td>\n",
       "      <td>0.239209</td>\n",
       "      <td>-1.215487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>50605.27</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.018774</td>\n",
       "      <td>0.078201</td>\n",
       "      <td>0.239209</td>\n",
       "      <td>-1.215487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>13740.12</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.018774</td>\n",
       "      <td>0.078201</td>\n",
       "      <td>0.239209</td>\n",
       "      <td>-1.215487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>39954.04</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.018774</td>\n",
       "      <td>0.078201</td>\n",
       "      <td>0.239209</td>\n",
       "      <td>-1.215487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>32229.38</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.018774</td>\n",
       "      <td>0.078201</td>\n",
       "      <td>0.239209</td>\n",
       "      <td>-1.215487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421565</th>\n",
       "      <td>45</td>\n",
       "      <td>93</td>\n",
       "      <td>2487.80</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-10-26</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.539003</td>\n",
       "      <td>0.379281</td>\n",
       "      <td>-0.303489</td>\n",
       "      <td>1.294317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421566</th>\n",
       "      <td>45</td>\n",
       "      <td>94</td>\n",
       "      <td>5203.31</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-10-26</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.539003</td>\n",
       "      <td>0.379281</td>\n",
       "      <td>-0.303489</td>\n",
       "      <td>1.294317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421567</th>\n",
       "      <td>45</td>\n",
       "      <td>95</td>\n",
       "      <td>56017.47</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-10-26</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.539003</td>\n",
       "      <td>0.379281</td>\n",
       "      <td>-0.303489</td>\n",
       "      <td>1.294317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421568</th>\n",
       "      <td>45</td>\n",
       "      <td>97</td>\n",
       "      <td>6817.48</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-10-26</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.539003</td>\n",
       "      <td>0.379281</td>\n",
       "      <td>-0.303489</td>\n",
       "      <td>1.294317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421569</th>\n",
       "      <td>45</td>\n",
       "      <td>98</td>\n",
       "      <td>1076.80</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-10-26</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.539003</td>\n",
       "      <td>0.379281</td>\n",
       "      <td>-0.303489</td>\n",
       "      <td>1.294317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>421570 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Store  Dept  Weekly_Sales  IsHoliday    DateTime  Week  Month  \\\n",
       "0           1     1      24924.50          0  2010-02-05     5      2   \n",
       "1           1     2      50605.27          0  2010-02-05     5      2   \n",
       "2           1     3      13740.12          0  2010-02-05     5      2   \n",
       "3           1     4      39954.04          0  2010-02-05     5      2   \n",
       "4           1     5      32229.38          0  2010-02-05     5      2   \n",
       "...       ...   ...           ...        ...         ...   ...    ...   \n",
       "421565     45    93       2487.80          0  2012-10-26    43     10   \n",
       "421566     45    94       5203.31          0  2012-10-26    43     10   \n",
       "421567     45    95      56017.47          0  2012-10-26    43     10   \n",
       "421568     45    97       6817.48          0  2012-10-26    43     10   \n",
       "421569     45    98       1076.80          0  2012-10-26    43     10   \n",
       "\n",
       "        SpecialDay  Type_A  Type_B  Type_C       CPI  Unemployment      Size  \\\n",
       "0               -1       1       0       0  1.018774      0.078201  0.239209   \n",
       "1               -1       1       0       0  1.018774      0.078201  0.239209   \n",
       "2               -1       1       0       0  1.018774      0.078201  0.239209   \n",
       "3               -1       1       0       0  1.018774      0.078201  0.239209   \n",
       "4               -1       1       0       0  1.018774      0.078201  0.239209   \n",
       "...            ...     ...     ...     ...       ...           ...       ...   \n",
       "421565          -1       0       1       0  0.539003      0.379281 -0.303489   \n",
       "421566          -1       0       1       0  0.539003      0.379281 -0.303489   \n",
       "421567          -1       0       1       0  0.539003      0.379281 -0.303489   \n",
       "421568          -1       0       1       0  0.539003      0.379281 -0.303489   \n",
       "421569          -1       0       1       0  0.539003      0.379281 -0.303489   \n",
       "\n",
       "            Year  \n",
       "0      -1.215487  \n",
       "1      -1.215487  \n",
       "2      -1.215487  \n",
       "3      -1.215487  \n",
       "4      -1.215487  \n",
       "...          ...  \n",
       "421565  1.294317  \n",
       "421566  1.294317  \n",
       "421567  1.294317  \n",
       "421568  1.294317  \n",
       "421569  1.294317  \n",
       "\n",
       "[421570 rows x 15 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/walmart-preprocessing.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-suffering",
   "metadata": {},
   "source": [
    "#### 2. Define X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "perceived-dylan",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop([\"Weekly_Sales\",\"DateTime\"],axis=1)\n",
    "y = data[\"Weekly_Sales\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "municipal-thompson",
   "metadata": {},
   "source": [
    "#### 3. Features Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sunset-fight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>Weekly_Sales</td>   <th>  R-squared:         </th>  <td>   0.090</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.089</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   3454.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 26 Apr 2021</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:15:20</td>     <th>  Log-Likelihood:    </th> <td>-4.8070e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>421570</td>      <th>  AIC:               </th>  <td>9.614e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>421557</td>      <th>  BIC:               </th>  <td>9.614e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    12</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>        <td>  1.03e+04</td> <td>  142.214</td> <td>   72.446</td> <td> 0.000</td> <td>    1e+04</td> <td> 1.06e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Store</th>        <td> -143.3891</td> <td>    3.051</td> <td>  -47.003</td> <td> 0.000</td> <td> -149.368</td> <td> -137.410</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Dept</th>         <td>  110.3523</td> <td>    1.095</td> <td>  100.737</td> <td> 0.000</td> <td>  108.205</td> <td>  112.499</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>IsHoliday</th>    <td> 1659.7048</td> <td>  306.748</td> <td>    5.411</td> <td> 0.000</td> <td> 1058.488</td> <td> 2260.922</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Week</th>         <td> -103.3617</td> <td>   27.496</td> <td>   -3.759</td> <td> 0.000</td> <td> -157.253</td> <td>  -49.471</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Month</th>        <td>  645.5361</td> <td>  119.408</td> <td>    5.406</td> <td> 0.000</td> <td>  411.501</td> <td>  879.571</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SpecialDay</th>   <td> -363.7994</td> <td>  123.572</td> <td>   -2.944</td> <td> 0.003</td> <td> -605.997</td> <td> -121.602</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Type_A</th>       <td> 1613.6161</td> <td>   90.111</td> <td>   17.907</td> <td> 0.000</td> <td> 1437.002</td> <td> 1790.230</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Type_B</th>       <td> 1252.7281</td> <td>   65.907</td> <td>   19.007</td> <td> 0.000</td> <td> 1123.552</td> <td> 1381.904</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Type_C</th>       <td> 7436.4425</td> <td>  127.610</td> <td>   58.275</td> <td> 0.000</td> <td> 7186.331</td> <td> 7686.554</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CPI</th>          <td> -944.2025</td> <td>   36.147</td> <td>  -26.121</td> <td> 0.000</td> <td>-1015.050</td> <td> -873.355</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Unemployment</th> <td> -436.4870</td> <td>   36.871</td> <td>  -11.838</td> <td> 0.000</td> <td> -508.753</td> <td> -364.221</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Size</th>         <td> 6027.3142</td> <td>   58.112</td> <td>  103.718</td> <td> 0.000</td> <td> 5913.416</td> <td> 6141.213</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Year</th>         <td> -104.1357</td> <td>   35.540</td> <td>   -2.930</td> <td> 0.003</td> <td> -173.792</td> <td>  -34.479</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>296928.884</td> <th>  Durbin-Watson:     </th>  <td>   1.321</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>   <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>9030579.636</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>            <td> 3.020</td>   <th>  Prob(JB):          </th>  <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>        <td>24.855</td>   <th>  Cond. No.          </th>  <td>1.47e+16</td>  \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 7.53e-24. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:           Weekly_Sales   R-squared:                       0.090\n",
       "Model:                            OLS   Adj. R-squared:                  0.089\n",
       "Method:                 Least Squares   F-statistic:                     3454.\n",
       "Date:                Mon, 26 Apr 2021   Prob (F-statistic):               0.00\n",
       "Time:                        18:15:20   Log-Likelihood:            -4.8070e+06\n",
       "No. Observations:              421570   AIC:                         9.614e+06\n",
       "Df Residuals:                  421557   BIC:                         9.614e+06\n",
       "Df Model:                          12                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "const          1.03e+04    142.214     72.446      0.000       1e+04    1.06e+04\n",
       "Store         -143.3891      3.051    -47.003      0.000    -149.368    -137.410\n",
       "Dept           110.3523      1.095    100.737      0.000     108.205     112.499\n",
       "IsHoliday     1659.7048    306.748      5.411      0.000    1058.488    2260.922\n",
       "Week          -103.3617     27.496     -3.759      0.000    -157.253     -49.471\n",
       "Month          645.5361    119.408      5.406      0.000     411.501     879.571\n",
       "SpecialDay    -363.7994    123.572     -2.944      0.003    -605.997    -121.602\n",
       "Type_A        1613.6161     90.111     17.907      0.000    1437.002    1790.230\n",
       "Type_B        1252.7281     65.907     19.007      0.000    1123.552    1381.904\n",
       "Type_C        7436.4425    127.610     58.275      0.000    7186.331    7686.554\n",
       "CPI           -944.2025     36.147    -26.121      0.000   -1015.050    -873.355\n",
       "Unemployment  -436.4870     36.871    -11.838      0.000    -508.753    -364.221\n",
       "Size          6027.3142     58.112    103.718      0.000    5913.416    6141.213\n",
       "Year          -104.1357     35.540     -2.930      0.003    -173.792     -34.479\n",
       "==============================================================================\n",
       "Omnibus:                   296928.884   Durbin-Watson:                   1.321\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          9030579.636\n",
       "Skew:                           3.020   Prob(JB):                         0.00\n",
       "Kurtosis:                      24.855   Cond. No.                     1.47e+16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 7.53e-24. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "x = sm.add_constant(X)\n",
    "sum_ = sm.OLS(y,x).fit()\n",
    "sum_.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atlantic-compatibility",
   "metadata": {},
   "source": [
    "You can see that in the preprocessing notebook, we dropped the irrelavant data out. So the above statistics are better when seeing its individual p-value. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-polymer",
   "metadata": {},
   "source": [
    "#### 4. Split the data into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "magnetic-arcade",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cross-acrylic",
   "metadata": {},
   "source": [
    "#### 5. Build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "lesbian-signal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9754747637394521"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(n_jobs=-1)\n",
    "rf.fit(X_train,y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "rf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-manner",
   "metadata": {},
   "source": [
    "#### 6. Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acute-spending",
   "metadata": {},
   "source": [
    "Regression model evaluation metrics\n",
    "\n",
    "1. Root Mean Sqaure Error (RMSE).\n",
    "2. Mean Absolute Error (MAE).\n",
    "3. R^2 (R-Square) or coefficient of determination.\n",
    "4. Cross validation: accuracy.\n",
    "5. Wright Mean Abosolute Error (WMAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "computational-still",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,r2_score,mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def evaluate_model(dataset,model,y_test,y_pred,X=None,y=None):\n",
    "    rmse = mean_squared_error(y_test,y_pred,squared=False)\n",
    "    mae = mean_absolute_error(y_test,y_pred)\n",
    "    r2 = r2_score(y_test,y_pred)\n",
    "    weights = dataset.IsHoliday.apply(lambda x: 5 if x else 1)\n",
    "    wmae = np.round(np.sum(weights*abs(y_test-y_pred))/(np.sum(weights)), 2)\n",
    "    print(f\"Root Mean Squared Error: {rmse:.2f}\")\n",
    "    print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "    print(f\"R-Squared: {r2*100:.2f}%\")\n",
    "    print(f\"Weight Mean Absolute Error: {wmae:.2f}\")\n",
    "    if X is not None and y is not None:\n",
    "        cvs_acc = cross_val_score(model,X,y,cv=5)\n",
    "        print(f\"The cross validation accuracy: {np.mean(cvs_acc)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "recorded-architecture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 3589.37\n",
      "Mean Absolute Error: 1394.33\n",
      "R-Squared: 97.55%\n",
      "Weight Mean Absolute Error: 319.25\n",
      "The cross validation accuracy: 71.21%\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(X,rf,y_test,y_pred,X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "criminal-financing",
   "metadata": {},
   "source": [
    "#### Additional-Features Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "sorted-vintage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(5,5))\n",
    "\n",
    "sorted_idx = rf.feature_importances_.argsort()\n",
    "ax.barh(X.columns[sorted_idx], rf.feature_importances_[sorted_idx])\n",
    "ax.set_title(f\"Random Forest Feature Importance\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "renewable-share",
   "metadata": {},
   "source": [
    "#### 7. Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "viral-alias",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(rf, open(\"models/RandomForestModel.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "several-judges",
   "metadata": {},
   "source": [
    "#### 8. Tune the model with Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving-consistency",
   "metadata": {},
   "source": [
    "To tune the model parameters, we can't use all the data because it will take long long time to run all possible combination. So we decide to use only 10 percent of the data to find the best parameters. This time we use GridSearchCV to perform the tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "weird-luther",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_10 = data.sample(int(len(data)*0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "twenty-oasis",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_10 = data_10.drop([\"Weekly_Sales\",\"DateTime\"],axis=1)\n",
    "y_10 = data_10[\"Weekly_Sales\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "unique-bridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_10,X_test_10,y_train_10,y_test_10 = train_test_split(X_10,y_10,test_size=0.2,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "about-haiti",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.6s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.6s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.7s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   4.9s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   4.7s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   4.7s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   4.7s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   4.6s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  11.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  10.9s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  10.9s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  10.9s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=  11.0s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   4.7s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   4.6s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   4.8s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   4.7s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   4.7s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=500; total time=  11.4s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=500; total time=  11.1s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=500; total time=  10.9s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=500; total time=  10.9s\n",
      "[CV] END max_depth=20, max_features=auto, min_samples_leaf=4, min_samples_split=4, n_estimators=500; total time=  10.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   3.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   3.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   3.7s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   3.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time=   3.7s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   1.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   1.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   1.5s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   1.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=200; total time=   1.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=500; total time=   3.5s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=500; total time=   3.5s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=500; total time=   3.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=500; total time=   3.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=500; total time=   3.5s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV,train_test_split\n",
    "\n",
    "grid = {\"n_estimators\":[100,200,500],\n",
    "       \"max_depth\":[20],\n",
    "       \"max_features\":[\"auto\",\"sqrt\"],\n",
    "       \"min_samples_split\":[2,4],\n",
    "       \"min_samples_leaf\":[4]}\n",
    "\n",
    "model = RandomForestRegressor(n_jobs=-1)\n",
    "\n",
    "gs_model = GridSearchCV(estimator=model,\n",
    "                       param_grid=grid,\n",
    "                       cv=5,\n",
    "                       verbose=2)\n",
    "\n",
    "gs_model.fit(X_train_10,y_train_10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ranging-buffalo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 20,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 4,\n",
       " 'min_samples_split': 4,\n",
       " 'n_estimators': 200}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "complimentary-antarctica",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_y_preds = gs_model.predict(X_test_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "featured-campus",
   "metadata": {},
   "source": [
    "#### 8. Use the best parameters to build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "lucky-psychiatry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9720029927860587"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_best_params = RandomForestRegressor(max_depth=20,\n",
    "                           max_features=\"auto\",\n",
    "                           min_samples_leaf=4,\n",
    "                           min_samples_split=4,\n",
    "                           n_estimators=500,\n",
    "                           n_jobs=-1)\n",
    "rf_best_params.fit(X_train,y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "rf_best_params.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "demonstrated-bidding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 3589.37\n",
      "Mean Absolute Error: 1394.33\n",
      "R-Squared: 97.55%\n",
      "Weight Mean Absolute Error: 319.25\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(X,rf_best_params,y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspected-shift",
   "metadata": {},
   "source": [
    "As you can see the best scores are from the first model that we built with defualt parameters. That's why Random Forest is a good model and easy to use because the defualt model usually gives the good result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latest-aggregate",
   "metadata": {},
   "source": [
    "#### 9. Try with other models\n",
    "\n",
    "1. Linear Regression.\n",
    "2. K-Nearest Neighbors.\n",
    "3. Decision Tree .\n",
    "4. Artificial Neural Networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "moderate-stuff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 21831.84\n",
      "Mean Absolute Error: 14597.85\n",
      "R-Squared: 9.27%\n",
      "Weight Mean Absolute Error: 2965.92\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train,y_train)\n",
    "y_reg = reg.predict(X_test)\n",
    "evaluate_model(X,reg,y_test,y_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "departmental-aurora",
   "metadata": {},
   "source": [
    "As we can see from RMSE of Linear Regression, the output is not good enough because the some columns in the data might not be a linear. So when we apply Linear Regression to perform a model, the output is what we expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "developed-filename",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 12552.49\n",
      "Mean Absolute Error: 6873.98\n",
      "R-Squared: 70.01%\n",
      "Weight Mean Absolute Error: 1519.88\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor # KSN\n",
    "\n",
    "knn = KNeighborsRegressor()\n",
    "knn.fit(X_train,y_train)\n",
    "y_knn = knn.predict(X_test)\n",
    "evaluate_model(X,knn,y_test,y_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dying-stranger",
   "metadata": {},
   "source": [
    "As we can see from RMSE of K-Nearest Neighbors, the output is better than Linear Regression but it's not that good. Maybe the data might perform well in this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "expanded-nicholas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 4484.43\n",
      "Mean Absolute Error: 1720.65\n",
      "R-Squared: 96.17%\n",
      "Weight Mean Absolute Error: 391.04\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dt = DecisionTreeRegressor()\n",
    "dt.fit(X_train,y_train)\n",
    "y_dt = dt.predict(X_test)\n",
    "evaluate_model(X,dt,y_test,y_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "false-chassis",
   "metadata": {},
   "source": [
    "As we can see from RMSE of Decision Tree, we get the better score compare to the two models before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cellular-commons",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "33726/33726 [==============================] - 23s 685us/step - loss: 489719988.2805 - mean_squared_error: 489719988.2805 - val_loss: 426777568.0000 - val_mean_squared_error: 426777568.0000\n",
      "Epoch 2/150\n",
      "33726/33726 [==============================] - 24s 713us/step - loss: 413646636.8837 - mean_squared_error: 413646636.8837 - val_loss: 407095936.0000 - val_mean_squared_error: 407095936.0000\n",
      "Epoch 3/150\n",
      "33726/33726 [==============================] - 22s 665us/step - loss: 396083237.5438 - mean_squared_error: 396083237.5438 - val_loss: 398697216.0000 - val_mean_squared_error: 398697216.0000\n",
      "Epoch 4/150\n",
      "33726/33726 [==============================] - 24s 711us/step - loss: 392965305.9583 - mean_squared_error: 392965305.9583 - val_loss: 391564256.0000 - val_mean_squared_error: 391564256.0000\n",
      "Epoch 5/150\n",
      "33726/33726 [==============================] - 26s 773us/step - loss: 378137601.3798 - mean_squared_error: 378137601.3798 - val_loss: 385215776.0000 - val_mean_squared_error: 385215712.0000\n",
      "Epoch 6/150\n",
      "33726/33726 [==============================] - 29s 853us/step - loss: 372731923.6159 - mean_squared_error: 372731923.6045 - val_loss: 381632768.0000 - val_mean_squared_error: 381632768.0000\n",
      "Epoch 7/150\n",
      "33726/33726 [==============================] - 29s 857us/step - loss: 368581059.1481 - mean_squared_error: 368581059.1481 - val_loss: 377306048.0000 - val_mean_squared_error: 377306048.0000\n",
      "Epoch 8/150\n",
      "33726/33726 [==============================] - 24s 713us/step - loss: 366861775.8933 - mean_squared_error: 366861782.3527 - val_loss: 374188832.0000 - val_mean_squared_error: 374188832.0000\n",
      "Epoch 9/150\n",
      "33726/33726 [==============================] - 24s 704us/step - loss: 368145322.8722 - mean_squared_error: 368145322.8722 - val_loss: 372887936.0000 - val_mean_squared_error: 372887936.0000\n",
      "Epoch 10/150\n",
      "33726/33726 [==============================] - 24s 713us/step - loss: 366060043.1047 - mean_squared_error: 366060043.1066 - val_loss: 367875904.0000 - val_mean_squared_error: 367875936.0000\n",
      "Epoch 11/150\n",
      "33726/33726 [==============================] - 25s 727us/step - loss: 355962330.7674 - mean_squared_error: 355962330.7674 - val_loss: 374138336.0000 - val_mean_squared_error: 374138336.0000\n",
      "Epoch 12/150\n",
      "33726/33726 [==============================] - 25s 733us/step - loss: 368685774.8036 - mean_squared_error: 368685774.8040 - val_loss: 364986848.0000 - val_mean_squared_error: 364986848.0000\n",
      "Epoch 13/150\n",
      "33726/33726 [==============================] - 26s 775us/step - loss: 359753103.8605 - mean_squared_error: 359753103.8605 - val_loss: 363445600.0000 - val_mean_squared_error: 363445600.0000\n",
      "Epoch 14/150\n",
      "33726/33726 [==============================] - 26s 781us/step - loss: 358709607.3532 - mean_squared_error: 358709607.3532 - val_loss: 361623968.0000 - val_mean_squared_error: 361623968.0000\n",
      "Epoch 15/150\n",
      "33726/33726 [==============================] - 25s 744us/step - loss: 355734752.8383 - mean_squared_error: 355734752.8383 - val_loss: 361647616.0000 - val_mean_squared_error: 361647616.0000\n",
      "Epoch 16/150\n",
      "33726/33726 [==============================] - 25s 731us/step - loss: 354073822.5000 - mean_squared_error: 354073827.7326 - val_loss: 356963776.0000 - val_mean_squared_error: 356963776.0000\n",
      "Epoch 17/150\n",
      "33726/33726 [==============================] - 25s 739us/step - loss: 351192937.8418 - mean_squared_error: 351192937.8418 - val_loss: 357373216.0000 - val_mean_squared_error: 357373216.0000\n",
      "Epoch 18/150\n",
      "33726/33726 [==============================] - 26s 762us/step - loss: 346644937.9136 - mean_squared_error: 346644937.9293 - val_loss: 353403936.0000 - val_mean_squared_error: 353403936.0000\n",
      "Epoch 19/150\n",
      "33726/33726 [==============================] - 27s 808us/step - loss: 346782396.6401 - mean_squared_error: 346782396.6240 - val_loss: 351438176.0000 - val_mean_squared_error: 351438176.0000\n",
      "Epoch 20/150\n",
      "33726/33726 [==============================] - 26s 781us/step - loss: 346065408.0417 - mean_squared_error: 346065406.9468 - val_loss: 351216960.0000 - val_mean_squared_error: 351216960.0000\n",
      "Epoch 21/150\n",
      "33726/33726 [==============================] - 23s 672us/step - loss: 346794590.0777 - mean_squared_error: 346794590.0796 - val_loss: 348718656.0000 - val_mean_squared_error: 348718656.0000\n",
      "Epoch 22/150\n",
      "33726/33726 [==============================] - 23s 671us/step - loss: 339915906.4805 - mean_squared_error: 339915906.4824 - val_loss: 347644992.0000 - val_mean_squared_error: 347644992.0000\n",
      "Epoch 23/150\n",
      "33726/33726 [==============================] - 25s 734us/step - loss: 337677874.9194 - mean_squared_error: 337677874.9194 - val_loss: 346506464.0000 - val_mean_squared_error: 346506464.0000\n",
      "Epoch 24/150\n",
      "33726/33726 [==============================] - 26s 785us/step - loss: 345749182.9781 - mean_squared_error: 345749182.9895 - val_loss: 346344960.0000 - val_mean_squared_error: 346344960.0000\n",
      "Epoch 25/150\n",
      "33726/33726 [==============================] - 30s 880us/step - loss: 335880070.3028 - mean_squared_error: 335880067.9432 - val_loss: 350260288.0000 - val_mean_squared_error: 350260288.0000\n",
      "Epoch 26/150\n",
      "33726/33726 [==============================] - 24s 711us/step - loss: 343731010.9137 - mean_squared_error: 343731010.9137 - val_loss: 344318496.0000 - val_mean_squared_error: 344318496.0000\n",
      "Epoch 27/150\n",
      "33726/33726 [==============================] - 22s 664us/step - loss: 339327740.8899 - mean_squared_error: 339327740.8917 - val_loss: 343209504.0000 - val_mean_squared_error: 343209504.0000\n",
      "Epoch 28/150\n",
      "33726/33726 [==============================] - 24s 710us/step - loss: 333683805.6755 - mean_squared_error: 333683805.8073 - val_loss: 344974528.0000 - val_mean_squared_error: 344974528.0000\n",
      "Epoch 29/150\n",
      "33726/33726 [==============================] - 28s 826us/step - loss: 333716205.0758 - mean_squared_error: 333716205.0654 - val_loss: 342402016.0000 - val_mean_squared_error: 342402016.0000\n",
      "Epoch 30/150\n",
      "33726/33726 [==============================] - 27s 796us/step - loss: 331118006.2663 - mean_squared_error: 331118006.2682 - val_loss: 341632288.0000 - val_mean_squared_error: 341632288.0000\n",
      "Epoch 31/150\n",
      "33726/33726 [==============================] - 26s 758us/step - loss: 326039641.6177 - mean_squared_error: 326039645.7862 - val_loss: 339210880.0000 - val_mean_squared_error: 339210880.0000\n",
      "Epoch 32/150\n",
      "33726/33726 [==============================] - 27s 807us/step - loss: 330847123.5162 - mean_squared_error: 330847123.5162 - val_loss: 342756768.0000 - val_mean_squared_error: 342756768.0000\n",
      "Epoch 33/150\n",
      "33726/33726 [==============================] - 36s 1ms/step - loss: 331172245.5429 - mean_squared_error: 331172245.5429 - val_loss: 349395936.0000 - val_mean_squared_error: 349395936.0000\n",
      "Epoch 34/150\n",
      "33726/33726 [==============================] - 28s 842us/step - loss: 329944294.1994 - mean_squared_error: 329944294.1994 - val_loss: 339448320.0000 - val_mean_squared_error: 339448320.0000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Dense(units=50,input_dim=X_train.shape[1],activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(units=50,activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(units=1,activation=\"linear\"))\n",
    "model.compile(optimizer=\"adam\",loss='mean_squared_error',metrics=[\"mean_squared_error\"])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_mean_squared_error\",patience=3)\n",
    "\n",
    "r = model.fit(x=X_train,y=y_train,epochs=150,batch_size=10,validation_data=(X_test,y_test),callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "reverse-meter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 18424.11\n"
     ]
    }
   ],
   "source": [
    "_,mean_squared_error = model.evaluate(X_test,y_test,verbose=0)\n",
    "y_ann = model.predict(X_test).reshape(-1,)\n",
    "print(f\"Root Mean Squared Error: {np.sqrt(mean_squared_error):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-pioneer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
